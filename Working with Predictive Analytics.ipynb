{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d72bddb",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The purpose of the exercise is to demostrate how well we can do predictive analytics.  \n",
    "The process entails how to deal with missing values, different options of converting the categorical data into numbers to make\n",
    "prediction doable.   \n",
    "We will also look at how we can divide the Data into Test and Train, do feature scalling and finally we look at different types of predictive models.   \n",
    "The process will cover these roadmap:\n",
    "1. B/s understanding\n",
    "2. Data Understanding\n",
    "3. Data preparation\n",
    "4. Modelling\n",
    "5. Evaluation\n",
    "6. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41cc95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PythonLibraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe24934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex     bmi  children smoker     region      charges\n",
      "0    19  female  27.900         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770         1     no  southeast   1725.55230\n",
      "2    28    male  33.000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705         0     no  northwest  21984.47061\n",
      "4    32    male  28.880         0     no  northwest   3866.85520\n",
      "5    31  female  25.740         0     no  southeast   3756.62160\n",
      "6    46  female  33.440         1     no  southeast   8240.58960\n",
      "7    37  female  27.740         3     no  northwest   7281.50560\n",
      "8    37    male  29.830         2     no  northeast   6406.41070\n",
      "9    60  female  25.840         0     no  northwest  28923.13692\n",
      "10   25    male  26.220         0     no  northeast   2721.32080\n",
      "11   62  female  26.290         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400         0     no  southwest   1826.84300\n",
      "13   56  female  39.820         0     no  southeast  11090.71780\n",
      "14   27    male     NaN         0    yes  southeast  39611.75770\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "data = pd.read_csv(\"insurance.csv\")\n",
    "\n",
    "#see the first 15 lines of data\n",
    "print(data.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1853a54d",
   "metadata": {},
   "source": [
    "### Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76afa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check how many values are missing (NaN) before we apply the methods below \n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0cf11",
   "metadata": {},
   "source": [
    "##### Fill in the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c091d1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#option0 for dropping the entire column\n",
    "data = pd.read_csv(\"insurance.csv\") # reloading fresh dataset for option 0\n",
    "data.drop('bmi', axis = 1, inplace = True)\n",
    "#check how many values are missing (NaN) - after we dropped 'bmi'\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a046e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "##### Dropping NAN\n",
    "data = pd.read_csv(\"insurance.csv\") # reloading fresh dataset\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a0712",
   "metadata": {},
   "source": [
    "#### Filling NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e5edfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"insurance.csv\")\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(data['bmi'].values.reshape(-1, 1))\n",
    "data['bmi'] = imputer.transform(data['bmi'].values.reshape(-1, 1))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6997d13",
   "metadata": {},
   "source": [
    "#### Filling NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dc92df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age     sex        bmi  children smoker     region      charges\n",
      "0    19  female  27.900000         0    yes  southwest  16884.92400\n",
      "1    18    male  33.770000         1     no  southeast   1725.55230\n",
      "2    28    male  33.000000         3     no  southeast   4449.46200\n",
      "3    33    male  22.705000         0     no  northwest  21984.47061\n",
      "4    32    male  28.880000         0     no  northwest   3866.85520\n",
      "5    31  female  25.740000         0     no  southeast   3756.62160\n",
      "6    46  female  33.440000         1     no  southeast   8240.58960\n",
      "7    37  female  27.740000         3     no  northwest   7281.50560\n",
      "8    37    male  29.830000         2     no  northeast   6406.41070\n",
      "9    60  female  25.840000         0     no  northwest  28923.13692\n",
      "10   25    male  26.220000         0     no  northeast   2721.32080\n",
      "11   62  female  26.290000         0    yes  southeast  27808.72510\n",
      "12   23    male  34.400000         0     no  southwest   1826.84300\n",
      "13   56  female  39.820000         0     no  southeast  11090.71780\n",
      "14   27    male  30.658545         0    yes  southeast  39611.75770\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"insurance.csv\")\n",
    "data['bmi'].fillna(data['bmi'].mean(), inplace = True)\n",
    "print(data.head(15))\n",
    "#check how many values are missing (NaN) - after we filled in the NaN\n",
    "count_nan = data.isnull().sum() # the number of missing values for every column\n",
    "print(count_nan[count_nan > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cafc2",
   "metadata": {},
   "source": [
    "### Convert Categorical Data into Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a06157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas factorize function for label encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "Index(['southwest', 'southeast', 'northwest', 'northeast'], dtype='object')\n",
      "[0 1 1 2 2 1 1 2 3 2]\n",
      "{'southwest': 0, 'southeast': 1, 'northwest': 1, 'northeast': 2}\n"
     ]
    }
   ],
   "source": [
    "#create series for pandas\n",
    "\n",
    "region = data[\"region\"] # series \n",
    "region_encoded, region_categories = pd.factorize(region)\n",
    "factor_region_mapping = dict(zip(region_categories, region_encoded)) #mapping of encoded numbers and original categories. \n",
    "\n",
    "print(\"Pandas factorize function for label encoding with series\")  \n",
    "print(region[:10]) #original version \n",
    "print(region_categories) #list of categories\n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "print(factor_region_mapping) # print factor mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5fe3d",
   "metadata": {},
   "source": [
    "#### Option1: pandas get_dummies\n",
    "Maps each category to 0 (cold) or 1 (hot) = one hot encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "223ceed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas get_dummies function for one hot encoding with series\n",
      "0    southwest\n",
      "1    southeast\n",
      "2    southeast\n",
      "3    northwest\n",
      "4    northwest\n",
      "5    southeast\n",
      "6    southeast\n",
      "7    northwest\n",
      "8    northeast\n",
      "9    northwest\n",
      "Name: region, dtype: object\n",
      "   _northeast  _northwest  _southeast  _southwest\n",
      "0           0           0           0           1\n",
      "1           0           0           1           0\n",
      "2           0           0           1           0\n",
      "3           0           1           0           0\n",
      "4           0           1           0           0\n",
      "5           0           0           1           0\n",
      "6           0           0           1           0\n",
      "7           0           1           0           0\n",
      "8           1           0           0           0\n",
      "9           0           1           0           0\n"
     ]
    }
   ],
   "source": [
    "#create series for pandas\n",
    "region = data[\"region\"] # series \n",
    "region_encoded = pd.get_dummies(region, prefix='')\n",
    "\n",
    "print(\"Pandas get_dummies function for one hot encoding with series\")  \n",
    "\n",
    "print(region[:10]) #original version \n",
    "print(region_encoded[:10]) #encoded numbers for categories \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2eaaab",
   "metadata": {},
   "source": [
    "### option2: sklearn label encoding\n",
    "Maps each category to a different integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e52e5761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn label encoder results for sex:\n",
      "{'female': 0, 'male': 1}\n",
      "  sex\n",
      "0   0\n",
      "1   1\n",
      "2   1\n",
      "3   1\n",
      "4   1\n",
      "5   0\n",
      "6   0\n",
      "7   0\n",
      "8   1\n",
      "9   0\n",
      "Sklearn label encoder results for smoker:\n",
      "{'no': 0, 'yes': 1}\n",
      "  smoker\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "5      0\n",
      "6      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n"
     ]
    }
   ],
   "source": [
    "#create ndarray for label encodoing (sklearn)\n",
    "sex = data.iloc[:,1:2].values\n",
    "smoker = data.iloc[:,4:5].values\n",
    "\n",
    "#label encoder = le\n",
    "\n",
    "## le for sex\n",
    "le = LabelEncoder()\n",
    "sex[:,0] = le.fit_transform(sex[:,0])\n",
    "sex = pd.DataFrame(sex)\n",
    "sex.columns = ['sex']\n",
    "le_sex_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for sex:\")  \n",
    "print(le_sex_mapping)\n",
    "print(sex[:10])\n",
    "\n",
    "## le for smoker\n",
    "le = LabelEncoder()\n",
    "smoker[:,0] = le.fit_transform(smoker[:,0])\n",
    "smoker = pd.DataFrame(smoker)\n",
    "smoker.columns = ['smoker']\n",
    "le_smoker_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Sklearn label encoder results for smoker:\")  \n",
    "print(le_smoker_mapping)\n",
    "print(smoker[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b3fc9",
   "metadata": {},
   "source": [
    "### option3: sklearn one hot encoding\n",
    "Maps each category to 0 (cold) or 1 (hot) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1afbedce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn one hot encoder results for region:\n",
      "   northeast  northwest  southeast  southwest\n",
      "0        0.0        0.0        0.0        1.0\n",
      "1        0.0        0.0        1.0        0.0\n",
      "2        0.0        0.0        1.0        0.0\n",
      "3        0.0        1.0        0.0        0.0\n",
      "4        0.0        1.0        0.0        0.0\n",
      "5        0.0        0.0        1.0        0.0\n",
      "6        0.0        0.0        1.0        0.0\n",
      "7        0.0        1.0        0.0        0.0\n",
      "8        1.0        0.0        0.0        0.0\n",
      "9        0.0        1.0        0.0        0.0\n"
     ]
    }
   ],
   "source": [
    "#one hot encoder = ohe\n",
    "\n",
    "#create ndarray for one hot encodoing (sklearn)\n",
    "region = data.iloc[:,5:6].values #ndarray\n",
    "\n",
    "## ohe for region\n",
    "ohe = OneHotEncoder() \n",
    "\n",
    "region = ohe.fit_transform(region).toarray()\n",
    "region = pd.DataFrame(region)\n",
    "region.columns = ['northeast', 'northwest', 'southeast', 'southwest']\n",
    "print(\"Sklearn one hot encoder results for region:\")   \n",
    "print(region[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ded27c",
   "metadata": {},
   "source": [
    "### Dividing the Data into Test and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb57e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data together:\n",
    "\n",
    "##take the numerical data from the original data\n",
    "X_num = data[['age', 'bmi', 'children']].copy()\n",
    "\n",
    "##take the encoded data and add to numerical data\n",
    "X_final = pd.concat([X_num, region, sex, smoker], axis = 1)\n",
    "\n",
    "#define y as being the \"charges column\" from the original dataset\n",
    "y_final = data[['charges']].copy()\n",
    "\n",
    "#Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be0275",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61fb0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###normalized scaler (fit transform on train, fit only on test)\n",
    "#n_scaler = MinMaxScaler()\n",
    "#X_train = n_scaler.fit_transform(X_train.astype(np.float))\n",
    "#X_test= n_scaler.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "s_scaler = StandardScaler()\n",
    "X_train = s_scaler.fit_transform(X_train.astype(float))\n",
    "X_test= s_scaler.transform(X_test.astype(float))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f457f",
   "metadata": {},
   "source": [
    "### Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d2884f",
   "metadata": {},
   "source": [
    "### 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "854b7658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr.coef_: [[3624.36356197 1966.90473927  661.35603447  242.57758422  -29.49212715\n",
      "  -104.19142495  -99.14488063  -44.54996175 9310.54961689]]\n",
      "lr.intercept_: [13141.35083164]\n",
      "lr train score 0.728, lr test score: 0.786\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('lr train score %.3f, lr test score: %.3f' % (\n",
    "lr.score(X_train,y_train),\n",
    "lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864930e",
   "metadata": {},
   "source": [
    "### 2. Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21316052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly train score 0.828, poly test score: 0.870\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures (degree = 2)\n",
    "X_poly = poly.fit_transform(X_final)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y_final, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(float))\n",
    "X_test= sc.transform(X_test.astype(float))\n",
    "\n",
    "#fit model\n",
    "poly_lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = poly_lr.predict(X_train)\n",
    "y_test_pred = poly_lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('poly train score %.3f, poly test score: %.3f' % (\n",
    "poly_lr.score(X_train,y_train),\n",
    "poly_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade2446f",
   "metadata": {},
   "source": [
    "### 3. Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9d674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78e86d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
